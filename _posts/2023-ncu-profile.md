## Use nsight compute for DRAM profiling 

I use a single warp to load 4 cachelines (128 bytes) of data from global memory to shared memory
```
__shared__ float4 shared[32];
for(int i=WARPLANE; i<32; i=+32)
   shared[WARPLANE] = ((float4 *)ptr)[WARPLANE];
```
Then, we run:
```
TMPDIR=~ ncu --kernel-name test_cta_pip_kernel --metrics memory_l1_tag_requests_global,memory_l2_theoretical_sectors_global,memory_l2_theoretical_sectors_global_ideal,group:memory__dram_table python test.py
```
We expect above code will load 4 cachlines from DRAM to L2, then L1. Therefore, there should be 4 global transactions, with 4 cacheline and 16 sectors. 

Before profiling above code, let's look up each memory profiling metrics:
- memory_l1_tag_requests_global: Number of L1 tag requests generated by global memory instructions.
- memory_l2_theoretical_sectors_global: Theoretical number of sectors requested in L2 from global memory instructions.
- memory_l2_theoretical_sectors_global_ideal: Ideal number of sectors requested in L2 from global memory instructions, assuming each not predicated-off thread performed the operation.

I put them together as all of three metrics need to be use to complete the picture.
Let's try run the below code first:
```
__shared__ float4 shared[32];
if(WARPLANE < 2)
   shared[WARPLANE] = ((float4 *)ptr)[WARPLANE];
```
We got:
```
==PROF== Disconnected from process 2279672
[2279672] python3.11@127.0.0.1
  test_cta_pip_kernel(at::GenericPackedTensorAccessor<float, (unsigned long)4, at::RestrictPtrTraits, int>, float *, int) (1, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.0
    Section: Command line profiler metrics
    --------------------------------------------------- ------------ ------------
    Metric Name                                          Metric Unit Metric Value
    --------------------------------------------------- ------------ ------------
    dram__bytes_read.sum                                        byte          192
    dram__bytes_read.sum.pct_of_peak_sustained_elapsed             %         0.01
    dram__bytes_read.sum.per_second                     Mbyte/second        57.14
    dram__bytes_write.sum                                       byte            0
    dram__bytes_write.sum.pct_of_peak_sustained_elapsed            %            0
    dram__bytes_write.sum.per_second                     byte/second            0
    dram__sectors_read.sum                                    sector            6
    dram__sectors_write.sum                                   sector            0
    memory_l1_tag_requests_global                            sectors            1
    memory_l2_theoretical_sectors_global                     sectors            1
    memory_l2_theoretical_sectors_global_ideal               sectors            1
    --------------------------------------------------- ------------ ------------
```

```
__shared__ float4 shared[32];
if(WARPLANE < 4)
   shared[WARPLANE] = ((float4 *)ptr)[WARPLANE];
```
We got:
```
==PROF== Disconnected from process 2290926
[2290926] python3.11@127.0.0.1
  test_cta_pip_kernel(at::GenericPackedTensorAccessor<float, (unsigned long)4, at::RestrictPtrTraits, int>, float *, int) (1, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.0
    Section: Command line profiler metrics
    --------------------------------------------------- ------------ ------------
    Metric Name                                          Metric Unit Metric Value
    --------------------------------------------------- ------------ ------------
    dram__bytes_read.sum                                        byte          192
    dram__bytes_read.sum.pct_of_peak_sustained_elapsed             %         0.01
    dram__bytes_read.sum.per_second                     Mbyte/second        55.05
    dram__bytes_write.sum                                       byte            0
    dram__bytes_write.sum.pct_of_peak_sustained_elapsed            %            0
    dram__bytes_write.sum.per_second                     byte/second            0
    dram__sectors_read.sum                                    sector            6
    dram__sectors_write.sum                                   sector            0
    memory_l1_tag_requests_global                            sectors            1
    memory_l2_theoretical_sectors_global                     sectors            2
    memory_l2_theoretical_sectors_global_ideal               sectors            2
    --------------------------------------------------- ------------ ------------
```

```
__shared__ float4 shared[32];
if(WARPLANE < 6)
   shared[WARPLANE] = ((float4 *)ptr)[WARPLANE];
```
We got:
```
==PROF== Disconnected from process 2295888
[2295888] python3.11@127.0.0.1
  test_cta_pip_kernel(at::GenericPackedTensorAccessor<float, (unsigned long)4, at::RestrictPtrTraits, int>, float *, int) (1, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.0
    Section: Command line profiler metrics
    --------------------------------------------------- ------------ ------------
    Metric Name                                          Metric Unit Metric Value
    --------------------------------------------------- ------------ ------------
    dram__bytes_read.sum                                        byte          256
    dram__bytes_read.sum.pct_of_peak_sustained_elapsed             %         0.01
    dram__bytes_read.sum.per_second                     Mbyte/second        71.43
    dram__bytes_write.sum                                       byte            0
    dram__bytes_write.sum.pct_of_peak_sustained_elapsed            %            0
    dram__bytes_write.sum.per_second                     byte/second            0
    dram__sectors_read.sum                                    sector            8
    dram__sectors_write.sum                                   sector            0
    memory_l1_tag_requests_global                            sectors            1
    memory_l2_theoretical_sectors_global                     sectors            3
    memory_l2_theoretical_sectors_global_ideal               sectors            3
    --------------------------------------------------- ------------ ------------
```

```
__shared__ float4 shared[32];
if(WARPLANE < 8)
   shared[WARPLANE] = ((float4 *)ptr)[WARPLANE];
```
We got:
```
==PROF== Disconnected from process 2298305
[2298305] python3.11@127.0.0.1
  test_cta_pip_kernel(at::GenericPackedTensorAccessor<float, (unsigned long)4, at::RestrictPtrTraits, int>, float *, int) (1, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.0
    Section: Command line profiler metrics
    --------------------------------------------------- ------------ ------------
    Metric Name                                          Metric Unit Metric Value
    --------------------------------------------------- ------------ ------------
    dram__bytes_read.sum                                        byte          256
    dram__bytes_read.sum.pct_of_peak_sustained_elapsed             %         0.01
    dram__bytes_read.sum.per_second                     Mbyte/second        75.47
    dram__bytes_write.sum                                       byte            0
    dram__bytes_write.sum.pct_of_peak_sustained_elapsed            %            0
    dram__bytes_write.sum.per_second                     byte/second            0
    dram__sectors_read.sum                                    sector            8
    dram__sectors_write.sum                                   sector            0
    memory_l1_tag_requests_global                            sectors            1
    memory_l2_theoretical_sectors_global                     sectors            4
    memory_l2_theoretical_sectors_global_ideal               sectors            4
    --------------------------------------------------- ------------ ------------
```

From above 3 experiments, we can observe that
* `memory_l1_tag_requests_global` gives number of global transactions issued by warps. It is the same of the old metric `gld_transactions` if one is farmilar with deprecated `nvprof`. 
* Each request of a transaction load at least one sector, and at most 4 sectors. Based on one's code, it may have `memory_l2_theoretical_sectors_global_ideal` range from `memory_l1_tag_requests_global` ~ `memory_l1_tag_requests_global*4` as above experiments shows.
* If one's `memory_l2_theoretical_sectors_global` is the same of `memory_l2_theoretical_sectors_global_ideal`, one may have the access partern which is mostly efficient to load from DRAM

Now we profile the code which loads 4 cachelines, we got:
```
==PROF== Disconnected from process 2343877
[2343877] python3.11@127.0.0.1
  test_cta_pip_kernel(at::GenericPackedTensorAccessor<float, (unsigned long)4, at::RestrictPtrTraits, int>, float *, int) (1, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.0
    Section: Command line profiler metrics
    --------------------------------------------------- ------------ ------------
    Metric Name                                          Metric Unit Metric Value
    --------------------------------------------------- ------------ ------------
    dram__bytes_read.sum                                        byte          640
    dram__bytes_read.sum.pct_of_peak_sustained_elapsed             %         0.03
    dram__bytes_read.sum.per_second                     Mbyte/second       180.18
    dram__bytes_write.sum                                       byte            0
    dram__bytes_write.sum.pct_of_peak_sustained_elapsed            %            0
    dram__bytes_write.sum.per_second                     byte/second            0
    dram__sectors_read.sum                                    sector           20
    dram__sectors_write.sum                                   sector            0
    memory_l1_tag_requests_global                            sectors            4
    memory_l2_theoretical_sectors_global                     sectors           16
    memory_l2_theoretical_sectors_global_ideal               sectors           16
    --------------------------------------------------- ------------ ------------
```
The profile results show that we issue 4 transaction requests and those 4 requests load 16 sectors from the DRAM and it is the most efficient way of loading.

Another useful metric is:
- group:memory__dram_table
It includes 8 metrices:
```
dram__bytes_read.sum                         
dram__bytes_read.sum.pct_of_peak_sustained_elapsed 
dram__bytes_read.sum.per_second                   
dram__bytes_write.sum                            
dram__bytes_write.sum.pct_of_peak_sustained_elapsed
dram__bytes_write.sum.per_second                  
dram__sectors_read.sum                           
dram__sectors_write.sum                         
```
The `memory_l1_tag_requests_global` and `dram__sectors_read.sum` metrics do not necessarily have to match because they represent different stages of the memory hierarchy:
1. `memory_l1_tag_requests_global`: This metric represents the number of L1 cache requests for global memory. It indicates how many times your kernel tried to access global memory through L1 cache.

2. `dram__sectors_read.sum`: This metric represents the total number of DRAM sectors read during the kernel execution. It indicates how much data is actually read from the DRAM.

The discrepancy between these two metrics can arise due to various factors:
1. Caching mechanisms: When a memory request is made, the L1 cache is first checked. If the requested data is not in the cache, a cache miss occurs, and the data is fetched from DRAM. The memory_l1_tag_requests_global metric counts the total number of sectors requested from global memory, but some of these requests may be served by the cache without accessing DRAM. This can lead to fewer DRAM sectors being read than L1 cache requests.In the case of cache misses (or evictions): the requested data is not found in the L1 cache, the request will be forwarded to the L2 cache or eventually to the DRAM. This means that even though there might be fewer L1 cache requests, more DRAM sectors could be accessed due to cache misses.

2. Memory access patterns: Non-coalesced or non-contiguous memory access patterns can result in inefficient memory utilization. This can cause higher L1 cache requests compared to DRAM sectors read, as multiple threads may request the same data from DRAM but have different L1 cache requests.

3. Memory coalescing: The GPU hardware tries to coalesce memory accesses, combining multiple requests into a single memory transaction to improve efficiency. This can lead to a lower number of DRAM sectors read than L1 cache requests, as multiple requests are combined into a single DRAM transaction.

4. Other Memory Requests: The dram__sectors_read.sum metric measures the total number of sectors read from DRAM, which can include memory requests not related to the L1 cache, such as local memory accesses, constant memory accesses, or texture memory accesses.

Note: `dram__sectors_read.sum` always load in multiple of two sectors. I haven't seen this number is an odd number.

Those metrics are more straightforward and their example can be seen above
