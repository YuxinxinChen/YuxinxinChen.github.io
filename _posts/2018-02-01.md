
layout: post
title: "Notes on GPU"
data: 2017-12-10
tags: [reading notes, GPU]
comments: true
share: false
---

PGAS questions:

Memory coherency
1. I guess PGAS don’t allow the data copy of remote node, otherwise it is super hard to keep data coherency. If this is true?
2. So the memory read and write happens by direct read/write to remote node’s memory, bypassing the CPU. How the node who does get knows the data is arrived? How the node who is written knows the write finished? I remember the mechanism used like doorbell. A counter is set in advance, each piece of data finishes transferring, the counter decreases correspondingly. The transfer finishes when the counter hits zero. However, based on this assumption, first, what if two remote nodes try to mem_put to the same memory address. How to make sure the information is not overwritten? If we use lock to lock the data, then the CPU is actually involved. So either the remote CPU signal local CPU to lock the data, signal the local CPU to release the lock or the local CPU will spin on the lock until the write is finished. 
3. In most practice, is this the case, there are many one-side read and write to remote data which can be above 50% of total read and write?
4. how those remote shared data lock or remote atomic operations are implemented, are they bad?
5. how synchronization is implemented?
6. PGAS is a programming model, UPC is PGAS actual implementation following PGAS programming model.What is the relationship between GASNet and UPC?
7. There are different kinds of machine and networks, so the if we run UPC on different machine, we need to rewrite everything involved with the machines and networks. So this motivates GASNet, which is a middle part between hardware (networks, machine) and the languages, doing all the dirty stuff, making PGAS code probable. 
8. Reading GASNet paper about disable handler’s interruption. I believe GASNet choose the disable handler’s interruption instead using the atomic operation on CPU must have a reason. Could you explain more about handler and how handler works and why we need atomic handler? This might be important because GPU doesn’t provide an API to disable the handler. So we probably need to hack into GPU. 
9. So GASNet one-side memory operation says it doesn't require the involvment of receiver's CPU. However it also need active message communication? which involves reciever's CPU?

I have red https://gasnet.lbl.gov/upc_IPDPS06.pdf and understand the reason why GASNet based PGAS favors a small but more mount of messages communication style. The gain of this communication scheme is from pipelining the communication and computation: small but many messages expose more overlap ratio while the cost of sending more messages is relative low by very-near-hardware GASNet memory operations.

Then there is basic questions following:
1) Since all the experiments in that paper are conducted on CPU, is this true for GPU? Now the stuff I need to think about is, how GASNet works just for put and get operation, what is the different of CPU and GPU? I need to understand relative low level stuff to evaluate if GPU can do the same comparable to CPU?

2) If GPU can do as well as CPU, then small and many messages scheme is preferred. Giving the assumption, GPU will receive many small message along time, what is appropriate programming model?

I noticed there are some work been done on extending UPC for GPU computing and I have red the slices on SIAM conference on parallel processing for scientific computing in 2010. If it is possible, I hope I can have a direct talk with the person who was doing this project. 

A  Look into MVAPICH2:
1) Many systems today want to use systems that have both GPUs and high-speed networks such as InfiniBand, PROBLEM:  Lack of a common memory registration mechanism. Each device has to pin the host memory it will use.  SOLUTION: Both devices register a common host buffer. GPU copies data to this buffer, and the network adapter can directly read from this buffer (or vice-versa). Note that GPU-Direct does not allow you to bypass host memory

Things need to think about: So basically, CPU only need to deal with few threads. However, GPU wil deal with millions of threads. 
I can make a list of use cases and how they would be expressed in the CUDA+MPI abstraction and in the UPC abstraction. For instance:

- Synchronous transfer between thread on GPU and another thread on same GPU
- Synchronous transfer between thread on GPU and another thread on different GPU
- Asynchronous transfers like the previous two. How does the receiving thread know when the data arrives?
- Transfers between {warps, blocks} as well as threads
- Different kinds of barriers: within a block, within a GPU, across GPUs

MPI case (Given GPUDirect and Unified virtual address):
MPI\_Send(s\_buf\_d, size, MPI\_CHAR, 1, tag, MPI\_COMM\_WORLD);
Mpi\_Recv(r\_buf\_d, size, MPI\_CHAR, 0, tag, MPI\_COMM\_WORLD, &stat);

A figure![](https://github.com/YuxinxinChen/YuxinxinChen.github.io/blob/master/images/mpi_comp.png)
I think we also need to make a same graph for PGAS GASNet particularly.
Also from this results:![](https://github.com/YuxinxinChen/YuxinxinChen.github.io/blob/master/images/proming_mvapich.png)
Seems small message benefit more from near-hardware-memory transaction. So we could also expect that the same holds for PGAS.


So MPI should never touch the problem that it needs to manipulate millions of threads.
But for GPAS, let's assume that the theads concept in PGAS mapping to the threads in GPU, then first, there will be millions of threads.
Seond for the simple blocking put/get operation, how can you ask a thread on GPU block and resume at some event since event is a CPU thing. For non-blocking put/get operation, it even more complicated. However can you nonblocking a thread and ask it to pick some certain stuff afterwards. There is no promising and furture in GPU.

Second it worths to think about that you really want to map the thread in PGAS onto the thread in GPU, maybe a warp? a block? Where is the tradeoff, what is the application?


