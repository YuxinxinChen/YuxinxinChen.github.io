
layout: post
title: "Notes on GPU"
data: 2017-12-10
tags: [reading notes, GPU]
comments: true
share: false
---

PGAS questions:

Memory coherency
1. I guess PGAS don’t allow the data copy of remote node, otherwise it is super hard to keep data coherency. If this is true?
2. So the memory read and write happens by direct read/write to remote node’s memory, bypassing the CPU. How the node who does get knows the data is arrived? How the node who is written knows the write finished? I remember the mechanism used like doorbell. A counter is set in advance, each piece of data finishes transferring, the counter decreases correspondingly. The transfer finishes when the counter hits zero. However, based on this assumption, first, what if two remote nodes try to mem_put to the same memory address. How to make sure the information is not overwritten? If we use lock to lock the data, then the CPU is actually involved. So either the remote CPU signal local CPU to lock the data, signal the local CPU to release the lock or the local CPU will spin on the lock until the write is finished. 
3. In most practice, is this the case, there are many one-side read and write to remote data which can be above 50% of total read and write?
4. how those remote shared data lock or remote atomic operations are implemented, are they bad?
5. how synchronization is implemented?
6. PGAS is a programming model, UPC is PGAS actual implementation following PGAS programming model.What is the relationship between GASNet and UPC?
7. There are different kinds of machine and networks, so the if we run UPC on different machine, we need to rewrite everything involved with the machines and networks. So this motivates GASNet, which is a middle part between hardware (networks, machine) and the languages, doing all the dirty stuff, making PGAS code probable. 
8. Reading GASNet paper about disable handler’s interruption. I believe GASNet choose the disable handler’s interruption instead using the atomic operation on CPU must have a reason. Could you explain more about handler and how handler works and why we need atomic handler? This might be important because GPU doesn’t provide an API to disable the handler. So we probably need to hack into GPU. 

I have red https://gasnet.lbl.gov/upc_IPDPS06.pdf and understand the reason why GASNet based PGAS favors a small but more mount of messages communication style. The gain of this communication scheme is from pipelining the communication and computation: small but many messages expose more overlap ratio while the cost of sending more messages is relative low by very-near-hardware GASNet memory operations.

Then there is basic questions following:
1) Since all the experiments in that paper are conducted on CPU, is this true for GPU? Now the stuff I need to think about is, how GASNet works just for put and get operation, what is the different of CPU and GPU? I need to understand relative low level stuff to evaluate if GPU can do the same comparable to CPU?

2) If GPU can do as well as CPU, then small and many messages scheme is preferred. Giving the assumption, GPU will receive many small message along time, what is appropriate programming model?

I noticed there are some work been done on extending UPC for GPU computing and I have red the slices on SIAM conference on parallel processing for scientific computing in 2010. If it is possible, I hope I can have a direct talk with the person who was doing this project. 

A  Look into MVAPICH2:
1) Many systems today want to use systems that have both GPUs and high-speed networks such as InfiniBand, PROBLEM:  Lack of a common memory registration mechanism. Each device has to pin the host memory it will use.  SOLUTION: Both devices register a common host buffer. GPU copies data to this buffer, and the network adapter can directly read from this buffer (or vice-versa). Note that GPU-Direct does not allow you to bypass host memory
